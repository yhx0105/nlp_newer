{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "def edit_distance(s1,s2):\n",
    "    return distance.levenshtein(s1,s2)\n",
    "s1='string'\n",
    "s2='setting'\n",
    "print(edit_distance(s1,s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['你在干什么', '你在干啥子', '你在做什么', '你好啊']\n"
     ]
    }
   ],
   "source": [
    "s3=['你在干什么',\n",
    "    '你在干啥子',\n",
    "    '你在做什么',\n",
    "    '你好啊',\n",
    "    '我喜欢吃香蕉']\n",
    "target='你在干啥'\n",
    "results=list(filter (lambda x:edit_distance(x,target)<=3,s3))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(s1,s2):\n",
    "    def add_space(s):\n",
    "        return ' '.join(list(s))\n",
    "    \n",
    "    #将字中间加入空格\n",
    "    s1,s2=add_space(s1),add_space(s2)\n",
    "    cv=CountVectorizer(tokenizer=lambda s:s.split())\n",
    "    print('cv:',cv)\n",
    "    corpus=[s1,s2]\n",
    "    print('corpus:',corpus)\n",
    "    vectors=cv.fit_transform(corpus).toarray()\n",
    "    print('vectors',vectors)\n",
    "    #求交集\n",
    "    numerator=np.sum(np.min(vectors,axis=0))\n",
    "    print('numerator:',numerator)\n",
    "    #求并集\n",
    "    denominator=np.sum(np.max(vectors,axis=0))\n",
    "    print('denominator:',denominator)\n",
    "    #计算jaccard系数\n",
    "    return 1*numerator/denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv: CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=<function jaccard_similarity.<locals>.<lambda> at 0x000000C5E4A0D048>,\n",
      "        vocabulary=None)\n",
      "corpus: ['你 在 干 嘛 呢', '你 在 干 什 么 呢']\n",
      "vectors [[0 0 1 1 1 1 1]\n",
      " [1 1 1 1 0 1 1]]\n",
      "numerator: 4\n",
      "denominator: 7\n",
      "0.5714285714285714\n"
     ]
    }
   ],
   "source": [
    "s1='你在干嘛呢'\n",
    "s2='你在干什么呢'\n",
    "print(jaccard_similarity(s1,s2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TF发计算cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_similarity(s1,s2):\n",
    "    def add_space(s):\n",
    "        return ' '.join(list(s))\n",
    "    s1,s2=add_space(s1),add_space(s2)\n",
    "    cv=CountVectorizer(tokenizer=lambda s:s.split())\n",
    "    corpus=[s1,s2]\n",
    "    vectors=cv.fit_transform(corpus).toarray()\n",
    "    #计算TF系数\n",
    "    return np.dot(vectors[0],vectors[1])/(norm(vectors[0]*norm(vectors[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7302967433402215\n"
     ]
    }
   ],
   "source": [
    "print(tf_similarity(s1,s2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF也可以用来相似度分析？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_similarity(s1,s2):\n",
    "    def add_space(s):\n",
    "        return ' '.join(list(s))\n",
    "    #将字中间加入空格\n",
    "    s1,s2=add_space(s1),add_space(s2)\n",
    "    #转化为TF矩阵\n",
    "    cv=TfidfVectorizer(tokenizer=lambda s:s.split())\n",
    "    corpus=[s1,s2]\n",
    "    print('corpus:',corpus)\n",
    "    vectors=cv.fit_transform(corpus).toarray()\n",
    "    print('vectors:',vectors)\n",
    "    #计算TF系数\n",
    "    return np.dot(vectors[0],vectors[1])/(norm(vectors[0])*norm(vectors[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus: ['你 在 干 嘛 呢', '你 在 干 什 么 呢']\n",
      "vectors: [[0.         0.         0.4090901  0.4090901  0.57496187 0.4090901\n",
      "  0.4090901 ]\n",
      " [0.49844628 0.49844628 0.35464863 0.35464863 0.         0.35464863\n",
      "  0.35464863]]\n",
      "0.5803329846765686\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_similarity(s1,s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
