{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language_Detector_model_navie_bais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data.csv',encoding='utf8') as tf:\n",
    "    lines=tf.readlines()\n",
    "dataset=[]\n",
    "for line in lines:\n",
    "    dataset.append((line.strip()[:-3],line.strip()[-2:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1 december wereld aids dag voorlichting in zuidafrika over bieten taboes en optimisme',\n",
       "  'nl'),\n",
       " ('1 millón de afectados ante las inundaciones en sri lanka unicef está distribuyendo ayuda de emergencia srilanka',\n",
       "  'es')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of the trian_data_list:7253,len of the trian_class_list:7253,len of the test_data_list:1813,len of the test_class_list:1813\n"
     ]
    }
   ],
   "source": [
    "#分割测试集与训练集0.8的训练集，0.2的测试集\n",
    "textsize=0.8\n",
    "index=int(len(dataset)*textsize)+1\n",
    "train_list=dataset[:index]\n",
    "test_list=dataset[index:]\n",
    "train_data_list,train_class_list=zip(*train_list)\n",
    "test_data_list,test_class_list=zip(*test_list)\n",
    "print('len of the trian_data_list:{},len of the trian_class_list:{},len of the test_data_list:{},len of the test_class_list:{}'.format(len(train_data_list),\n",
    "                                                                                                                                       len(train_class_list),\n",
    "                                                                                                                                      len(test_data_list),\n",
    "                                                                                                                                      len(test_class_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of the trian_data_list:,len of the trian_class_list:\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def remove_nums(document):\n",
    "    pattern=re.compile('\\d+')\n",
    "    clean_text=re.sub(pattern,'',document)\n",
    "    return clean_text\n",
    "print(remove_nums('len of the trian_data_list:7253,len of the trian_class_list:7253'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(analyzer='char_wb', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=1000, min_df=1,\n",
      "        ngram_range=(1, 2),\n",
      "        preprocessor=<function remove_nums at 0x000000982CF25840>,\n",
      "        stop_words=None, strip_accents=None,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, vocabulary=None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer#这部分的原理是什么如何提取数据？提取的数据是什么样子\n",
    "vec=CountVectorizer(lowercase=True,analyzer='char_wb',\n",
    "                   ngram_range=(1,2),max_features=1000,\n",
    "                   preprocessor=remove_nums)\n",
    "vec.fit(train_data_list)\n",
    "print(vec.fit(train_data_list))\n",
    "def get_features(x):\n",
    "    vec.transform(x)#拟合模型，并返回文本矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#导入分类器进行训练\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier=MultinomialNB()\n",
    "classifier.fit(vec.transform(train_data_list),train_class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9762824048538334"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(vec.transform(test_data_list),test_class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['de'], dtype='<U2')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence=['visite berlin']\n",
    "classifier.predict(vec.transform(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
